<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Un estudio demostró que los modelos de inteligencia artificial como GPT son capaces de efectuar ciberataques de manera autónoma</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <h1>Un estudio demostró que los modelos de inteligencia artificial como GPT son capaces de efectuar ciberataques de manera autónoma</h1>
  <h2>Investigadores sometieron a diferentes modelos a pruebas para medir sus capacidades de hackeo, brindándoles descripciones de distintos tipos de vulnerabilidades comunes</h2>
  <p>Por ROSARIO3</p>
  <figure>
    <img src="https://www.consumoteca.com/wp-content/uploads/Pantalla-de-ordenador-con-codigo.jpg" alt="Imagen laptop">
    <figcaption>La inteligencia artificial representa nuevos riesgos en materia de ciberseguridad.</figcaption>
  </figure>
  
  <p>La inteligencia artificial representa nuevos riesgos en materia de ciberseguridad.</p>
  <p>Un grupo de investigadores que realizó pruebas con modelos de lenguaje grandes (LLM) demostró que los desarrollos de Inteligencia Artificial (IA) de este tipo, como GPT-4, son capaces de explotar vulnerabilidades de un día (one-day vulnerabilities), lo que representa una amenaza en materia de ciberseguridad.</p>
  <p>Los riesgos asociados a las herramientas de IA generativa que ya son utilizadas por millones de usuarios en todo el mundo siguen en plena investigación entre quienes se dedican a detectar las formas en las que ciberdelincuentes podrían servirse de estas tecnologías, que van desde la <a href='http://www.rosario3.com/tecnologia/Las-replicas-de-ChatGPT-disponibles-en-la-dark-web-potencian-las-estafas-de-ciberdelincuentes-con-inteligencia-artificial-20240123-0049.html'>redacción de correos falsos</a> hasta el <a href='http://www.rosario3.com/tecnologia/Afirman-que-mas-de-la-mitad-de-las-contrasenas-pueden-ser-hackeadas-en-menos-de-un-minuto-por-Inteligencia-Artificial-20230414-0021.html'>hackeo de contraseñas</a>.</p>
  <p>En este contexto, un grupo de investigadores de la Universidad de Illinois Urbana-Champaign (UIUC), en Estados Unidos, llevó a cabo pruebas para investigar la efectividad de distintos LLM para explotar las vulnerabilidades de ciberseguridad para las cuales hay parches o herramientas de mitigación disponibles.</p>
  <p>De aquí que a estas vulnerabilidades sean de "un día", lo que se refiere al período entre el momento en que se divulga la vulnerabilidad y aquel en el que generalmente se parchean los sistemas afectados. En cambio, las vulnerabilidades de día cero (cero-day vulnerabilities) se refieren a aquellas para las cuales no existe un parche o mitigación ya que son desconocidas, y que por lo tanto representan un riesgo y exposición mayores.</p>
  <figure>
    <img src="https://i.blogs.es/575118/gpt-4-que-es-cuando-sale-como-funciona/1366_2000.jpeg" alt="Imagen chatgpt">
    <figcaption>GPT-4 fue el único modelo capaz de explotar las vulnerabilidades de la prueba.</figcaption>
  </figure>
  <h1>Más baratos y eficaces</h1>
  <p>En sus pruebas, los investigadores proporcionaron a GPT-4 –el modelo de lenguaje disponible más avanzado de OpenAI– descripciones tomadas de la CVE, y demostraron que la IA tuvo una efectividad del 87% en la explotación de estas vulnerabilidades.</p>
  <p>Los demás modelos, como GPT-3.5, tuvieron un 0% de efectividad. Esto muestra que, entre una versión de la misma herramienta y la otra, sus capacidades de hackeo pasaron de ser nulas a altamente efectivas.</p>
  <p>El estudio encontró que GPT-4 solo falló al intentar explotar dos vulnerabilidades, identificadas como Iris XSS (de severidad media) y Hertzbeat RCE (una vulnerabilidad crítica). Sin embargo, a pesar de su alto rendimiento, los investigadores aclararon que GPT-4 necesitó la descripción detallada extraída de la CVE para explotar estas vulnerabilidades de forma eficaz. Sin esos detalles, sólo podría explotar el 7% de las vulnerabilidades de forma independiente.</p>
  <p>Pero lo importante es que el estudio concluyó que utilizar LLM para explotar vulnerabilidades es, en líneas generales, más barato y más eficiente que el trabajo humano.</p>
  <p>De acuerdo con estimaciones, utilizar un LLM cuesta aproximadamente 9 dólares por exploit, mientras que un experto en ciberseguridad cuesta alrededor de 50 dólares por hora y tarda 30 minutos por vulnerabilidad.</p>
  <p>Además, el estudio afirma que los agentes de LLM son "trivialmente escalables en contraste con el trabajo humano", lo que los hace posiblemente más efectivos que los piratas informáticos humanos.</p>
</body>
</html>
